{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i408TvfBOEKf"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kBwzhwFUNlEh",
        "outputId": "cca9c14a-f64d-476a-86bc-b809760a8b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/162.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'HW4P2_TA_Expts'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 25 (delta 8), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 20.77 KiB | 360.00 KiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummaryX -q\n",
        "!pip install jiwer\n",
        "!pip install python-Levenshtein -q\n",
        "!pip install -U transformers -q\n",
        "!git clone https://github.com/puru-samal/HW4P2_TA_Expts.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvMN9pIyj34_"
      },
      "source": [
        "# (Optional) If commiting to the repo, re-clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ae-h8UcqMNgW",
        "outputId": "b05e4ab8-ed7d-4bc3-c23e-c4c5da04b5b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'HW4P2_TA_Expts'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 47 (delta 25), reused 34 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (47/47), 24.35 KiB | 24.35 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/HW4P2_TA_Expts\n",
        "!git clone https://github.com/puru-samal/HW4P2_TA_Expts.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4qOuEiBOHbV"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XUtVlowWOIks",
        "outputId": "53f64dcf-1121-42d4-d44b-443518c343c1"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import numpy as np\n",
        "file = \"1-7QAa-SMqsm3lPhwQvGexoKQ-IkR0YIm\"\n",
        "url = f\"https://drive.google.com/uc?id={file}\"\n",
        "gdown.download(url, \"hw4p2.tar.gz\", quiet=False)\n",
        "!tar -xzvf hw4p2.tar.gz\n",
        "!rm -rf hw4p2.tar.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UR0tJNSpKa"
      },
      "source": [
        "# Setup Experiment\n",
        "Modify this config file based on the experiment assigned to you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke60hyU-SrSt",
        "outputId": "0233df25-86a6-4a7e-af28-6686b05b59c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting config_obj_3.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile config_obj_3.yaml\n",
        "\n",
        "Name: \"Gabby\"\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "root: \"\"\n",
        "train_partition: \"train-clean-100\"\n",
        "val_partition: \"dev-clean\"\n",
        "test_partition: \"test-clean\"\n",
        "NUM_WORKERS: 4\n",
        "subset: 0.1\n",
        "norm: True\n",
        "token_type: \"char\" # [char, 1k, 10k, 50k]\n",
        "input_dim: 80\n",
        "batch_size: 8\n",
        "#####  LM Parameters ----------------\n",
        "\n",
        "lm_epochs : 100\n",
        "\n",
        "###### Encoder Parameters ------------------------------------------\n",
        "embed_type: \"BiLSTM\" # Available: ['Conv1DMLP', 'ResBlockMLP', 'BiLSTM']\n",
        "enc_dropout: 0.1\n",
        "enc_num_layers: 2\n",
        "enc_num_heads: 8\n",
        "\n",
        "###### Decoder Parameters ------------------------------------------\n",
        "dec_dropout: 0.1\n",
        "dec_num_layers: 2\n",
        "dec_num_heads: 8\n",
        "\n",
        "###### Network Parameters ------------------------------------------------------\n",
        "d_model: 512\n",
        "d_ff: 2048\n",
        "\n",
        "###### Training Parameters ------------------------------------------------------\n",
        "learning_rate: 0.002\n",
        "optimizer: \"AdamW\"\n",
        "momentum: 0.0\n",
        "nesterov: True\n",
        "scheduler: \"CosineAnnealing\" # Available: ['CosineAnnealing', 'ReduceLR']\n",
        "factor: 0.2\n",
        "patience: 4\n",
        "epochs: 40\n",
        "calc_lev: true # Turn on Levenshtein distance calculation (SLOW!)\n",
        "\n",
        "###### SpecAugment ---------------------------------------------------------------\n",
        "specaug: false\n",
        "specaug_conf:\n",
        "  apply_time_warp: true\n",
        "  time_warp_window: 5\n",
        "  time_warp_mode: bicubic\n",
        "  apply_freq_mask: true\n",
        "  freq_mask_width_range: 30\n",
        "  num_freq_mask: 2\n",
        "  apply_time_mask: true\n",
        "  time_mask_width_range: 40\n",
        "  num_time_mask: 2\n",
        "\n",
        "###### Normalization ---------------------------------------------------------------\n",
        "global_mvn: true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5NpEHtTMnAh"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K94su5bjMmyK",
        "outputId": "ee6067b0-4aa3-446a-d1b6-6a0482f77bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n",
            "[Tokenizer Loaded]: char\n",
            "\tEOS_TOKEN:  0\n",
            "\tSOS_TOKEN:  0\n",
            "\tPAD_TOKEN:  1\n",
            "\tUNK_TOKEN:  2\n",
            "\tVOCAB_SIZE: 31\n",
            "Examples:\n",
            "\t[DECODE EOS, SOS, PAD, UNK]           : <|endoftext|><|endoftext|><|padding|><|unknown|>\n",
            "\t[Tokenize HELLO DEEP LEARNERS]        : ['H', 'E', 'L', 'L', 'O', ' ', 'D', 'E', 'E', 'P', ' ', 'L', 'E', 'A', 'R', 'N', 'E', 'R', 'S']\n",
            "\t[Encode (tensor) HELLO DEEP LEARNERS] : tensor([[10,  7, 14, 14, 17, 29,  6,  7,  7, 18, 29, 14,  7,  3, 20, 16,  7, 20,\n",
            "         21]])\n",
            "\t[Encode (list)   HELLO DEEP LEARNERS] : [10, 7, 14, 14, 17, 29, 6, 7, 7, 18, 29, 14, 7, 3, 20, 16, 7, 20, 21]\n",
            "\n",
            "Loading mfcc data for train-clean-100: 100%|█| 2853/2853 [00:00<00:00, 3642.00it\n",
            "Loading transcript data for train-clean-100: 100%|█| 2853/2853 [00:00<00:00, 103\n",
            "Computing global mean and variance for normalization\n"
          ]
        }
      ],
      "source": [
        "!python pretraining_main.py config_obj_3.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
